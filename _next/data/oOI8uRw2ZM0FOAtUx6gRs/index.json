{"pageProps":{"posts":[{"slug":"postgres-fun-file-imports","frontmatter":{"title":"Postgres Fun: Using File Import","date":"September 5, 2020","modified":"September 5, 2020","description":"First in PostgreSQL Series, using files to manage DB.","tags":["postgresql","fresh-dev"]},"excerpt":"","content":"\nAt The Climate Service (TCS), our relational database (DB) of choice is (PostgreSQL)[https://www.postgresql.org/] (pg). Before joining TCS, my experience had only been with NoSQL DBs, namely (MongoDB)[https://www.mongodb.com/]. It has been a journey so far to delve into everything that pg offers, I'll be sharing some of what I've found to be useful over the course of several entries.\n\n### TLDR\n\nWe are able to import DB data from files (assumes you have (Docker)[https://docs.docker.com/get-docker/]/(psql)[https://www.postgresql.org/download/] installed):\n\n- Clone and cd into this repo: `git clone XYZ && cd XYZ`\n- Start a local (pg instance with Docker)[https://hub.docker.com/_/postgres]: `docker run --name some-postgres -e POSTGRES_PASSWORD=mysecretpassword -d postgres`\n- Connect using psql: `psql -h localhost -p 5432 -U postgres -W`\n- Create a schema and tables using file import: `\\i db/schema.ddl`\n- \"Seed\" tables using file import: `\\i db/seed.sql`\n\n## Schema Management\n\nIf, like us at TCS, you employ methods like Agile/SCRUM, then your team is looking to build out feature sets through iteration. For us, as part of building \"Generation 2.0\" of our product, much of that also occurred within our DB schema, as our researchers continue to grow their own knowledge base surrounding the relationships between climate science and risk.\n\nFor the first few months, as we built out our DB schema, and tested how we modeled the relationships behind our data, we would pack everything in two files - gracefully named `schema.dll` and `seed.sql`. We had these under source control, so we could at least look back at changes to our git repository and understand the journey to now. This was due to our team's decision to not use an object-relational mapping library (such as (Sequelize)[https://sequelize.org/] or (TypeORM)[https://typeorm.io/] in relational-DB land, or an object data modeling (ODM) such as (Mongoose)[https://mongoosejs.com/] for the NoSQL-inclined) to start, to give us better flexibility while in this learning-by-doing period.\n\nIn practice this meant that any pull request (PR) with schema changes would lead to something like the following for each developer, first within one's local pg instance, subsequently as part of our build pipeline:\n\n```console\n> docker start local-postgres     #restart pg container, if process had been shut down.\n> psql local-postgres      #connect to docker pg instance using `psql` utility\n> \\i path/to/schema.dll     #import latest/greatest DB schema from file\n> \\i path/to/seed.sql       #import latest/greatest DB seed data from file\n```\n\nWhen I first started using this method, it blew my mind! Some of our more senior engineers were starting to discuss, and implement, infrastructure-as-code (IaC), but I had originally thought without the use of an ORM we'd receive DB updates through Slack and ad hoc document/update ourselves organically. Thankfully livelier minds were driving our project.\n\n## Next Steps, An Invitation to Migration\n\nAs you may have surmised, while this was great as we were ramping up, it quickly became a hinderance to have our DB - even a local Docker instance - doing its best phoenix impression whenever we added even a simple field to a table. Thankfully, our team now uses (Flyway)[https://flywaydb.org/getstarted/why] - so whenever Alice heads out on vacation, and Bob finishes his design for a time-saving DB trigger, Alice can quickly and safely update. All it takes is a `git pull` on our trunk branch, and a `flyway migrate` thereafter.\n\nMore on that to come! Does your team struggle with or have a great method for relational DB management?\n\n## That's it! Happy coding!\n"},{"slug":"intent","frontmatter":{"title":"Intent","date":"August 30, 2020","modified":"September 5, 2020","description":"Let's get inside, out.","tags":["self-accountability"]},"excerpt":"","content":"\n### I'll be writing here about building things with code, or other things that I've found to be interesting or of use.\n\n#### Upcoming writings\n\n- Using Tekton CLI\n- Small JS Patterns\n  - [x] Config Object\n- Postgres Fun\n  - [x] File Imports\n  - [ ] File Exports\n  - [ ] \"Beanstalk\" Tables\n  - [ ] Common Table Expressions\n  - [ ] Generating Tables and Triggers\n  - [ ] Methods to Soft Delete\n- Small Refactorings\n- Transition to Cypress\n- Using Cypress Commands\n"},{"slug":"js-config-object","frontmatter":{"title":"Small JS Patterns: Config Object","date":"August 16, 2020","modified":"September 5, 2020","description":"First in JS Patterns Series, fun use of spread operator.","tags":["js"]},"excerpt":"","content":"\nSharing here a quick JS pattern that I enjoy using when dealing with when representing some sort of configuration with an object.\n\n### TLDR\n\nWhen using objects, and assigning key-value pairs, placing array brackets - \\[ \\] – around a variable will evaluate that variable's value instead of using the variable name.\n\n## Using Configuration Objects\n\nThis pattern is vanilla JS, so let's open up our dev tools within your favorite browser. Create an object that represents potential filters on a movie/tv show selection site:\n\n```javascript\nlet filters = {\n  category: [\"Comedy\", \"Horror\", \"Sci-fi\", \"Anime\"],\n  maxDuration: 120,\n};\n```\n\nWe'll assume there is some data list/UI present that handles the possible values available to update this object, such as in this article.\n\nLet's create a function that handles updating our filters value:\n\n```javascript\nconst handleFiltersChange = (key, newValue) => {\n  filters = {\n    ...filters,\n    [key]: newValue,\n  };\n};\n```\n\nNote handleFiltersChange accepts two parameters to facilitate updates – both the key of the value to be updated and the new value. We are using the array bracket wrappers over our key values to evaluate the variable value instead of just updating our filter object with a literal 'key' value.\n\nLet's implement a counter-example without our square brackets to verify the difference:\n\n```javascript\nconst handleFiltersChangeJustKey = (key, newValue) => {\n  filters = {\n    ...filters,\n    key: newValue,\n  };\n};\n```\n\nChecking our original values persist:\n\n```console\n> filters\n{\n  category: ['Comedy', 'Horror', 'Sci-fi', 'Anime'],\n  maxDuration: 120\n}\n```\n\nCalling our second function, handleFiltersChangeJustKey:\n\n```console\n> handleFiltersChangeJustKey('maxDuration', 55)\n> filters\n\n{\n  category: ['Comedy', 'Horror', 'Sci-fi', 'Anime'],\n  maxDuration: 120, //expressed in minutes\n  key: 55\n}\n```\n\nWell, that's not the update we were looking for... Let's try calling our first function, handleFiltersChange:\n\n```console\n> handleFiltersChange ('maxDuration', 90)\n> filters\n\n{\n  category: ['Comedy', 'Horror', 'Sci-fi', 'Anime'],\n  maxDuration: 90,\n  key: 55\n}\n```\n\nCalling handleFiltersChange with a more complex data structure:\n\n```console\n> const newValues = ['Thriller', 'Drama', 'Romance']\n> handleFiltersChange ('category', newValues)\n> filters\n\n{\n  category: ['Thriller', 'Drama', 'Romance'],\n  maxDuration: 90,\n  key: 55\n}\n```\n\n## That's it! Happy coding!\n"}]},"__N_SSG":true}